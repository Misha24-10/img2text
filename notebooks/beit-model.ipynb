{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1462296,"sourceType":"datasetVersion","datasetId":857191}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport wandb\nfrom transformers import VisionEncoderDecoderModel, AutoTokenizer, AutoFeatureExtractor, Seq2SeqTrainer, Seq2SeqTrainingArguments\nfrom PIL import Image\nimport json\nfrom typing import Literal, Mapping","metadata":{"_uuid":"6b9a2076-770c-4a9a-afbb-228bef9bb7a6","_cell_guid":"79207cb1-6a50-43ad-8f72-94430ff428cc","collapsed":false,"execution":{"iopub.status.busy":"2024-05-18T22:28:57.360279Z","iopub.execute_input":"2024-05-18T22:28:57.360603Z","iopub.status.idle":"2024-05-18T22:29:16.618222Z","shell.execute_reply.started":"2024-05-18T22:28:57.360576Z","shell.execute_reply":"2024-05-18T22:29:16.617232Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from copy import deepcopy\nfrom transformers import Seq2SeqTrainer\nfrom torch import nn\nfrom typing import Dict, Union, Any\nfrom pprint import pprint\nimport random\nfrom transformers import DefaultDataCollator","metadata":{"_uuid":"633c5aa1-2538-4792-b5c0-55bdfc58989c","_cell_guid":"bcd9d753-5544-455f-9bae-2a430ce745d6","collapsed":false,"execution":{"iopub.status.busy":"2024-05-18T22:29:16.619761Z","iopub.execute_input":"2024-05-18T22:29:16.620492Z","iopub.status.idle":"2024-05-18T22:29:16.635101Z","shell.execute_reply.started":"2024-05-18T22:29:16.620455Z","shell.execute_reply":"2024-05-18T22:29:16.634095Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchmetrics.text import BLEUScore\nfrom torchmetrics.text.rouge import ROUGEScore","metadata":{"_uuid":"c9d147dc-8c1b-4406-a913-197cb3f73476","_cell_guid":"47894512-d38e-4044-aa3f-6c7d77a76104","collapsed":false,"execution":{"iopub.status.busy":"2024-05-18T22:29:16.636306Z","iopub.execute_input":"2024-05-18T22:29:16.636596Z","iopub.status.idle":"2024-05-18T22:29:18.441107Z","shell.execute_reply.started":"2024-05-18T22:29:16.636571Z","shell.execute_reply":"2024-05-18T22:29:18.440304Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\n\nuse_wandb = True\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\nos.environ[\"WANDB_DISABLED\"] = \"false\" if use_wandb else \"true\"\nos.environ[\"WANDB_PROJECT\"] = \"VIT_GPT\"\nif use_wandb:\n    user_secrets = UserSecretsClient()\n    wandb_api = user_secrets.get_secret(\"wandb\") \n    wandb.login(key=wandb_api)","metadata":{"_uuid":"d1624a79-2836-4e2a-a1e1-6b5247dd13db","_cell_guid":"d9336a6a-2383-4517-9f0b-e0391bab71ed","collapsed":false,"execution":{"iopub.status.busy":"2024-05-18T22:45:14.891249Z","iopub.execute_input":"2024-05-18T22:45:14.891891Z","iopub.status.idle":"2024-05-18T22:45:15.050984Z","shell.execute_reply.started":"2024-05-18T22:45:14.891856Z","shell.execute_reply":"2024-05-18T22:45:15.050072Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model and tokenizer\nimage_encoder_model = \"microsoft/beit-base-patch16-224-pt22k-ft22k\"\ntext_decode_model = \"GPT2\"","metadata":{"_uuid":"45493545-cf93-4a83-b276-5deb5dfab4be","_cell_guid":"f2362d7e-c612-4571-a55c-73af40dfff44","collapsed":false,"execution":{"iopub.status.busy":"2024-05-18T22:45:15.107172Z","iopub.execute_input":"2024-05-18T22:45:15.107941Z","iopub.status.idle":"2024-05-18T22:45:15.113442Z","shell.execute_reply.started":"2024-05-18T22:45:15.107899Z","shell.execute_reply":"2024-05-18T22:45:15.112415Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_extractor = AutoFeatureExtractor.from_pretrained(image_encoder_model)\ntext_tokenizer = AutoTokenizer.from_pretrained(text_decode_model)\nmodel = VisionEncoderDecoderModel.from_encoder_decoder_pretrained(image_encoder_model, text_decode_model)","metadata":{"_uuid":"d70b8f3d-f32a-4d76-862a-414f7e4d0e70","_cell_guid":"572828f8-d2f0-4693-8207-b4ff8d4d82a1","collapsed":false,"execution":{"iopub.status.busy":"2024-05-18T22:45:15.440052Z","iopub.execute_input":"2024-05-18T22:45:15.440405Z","iopub.status.idle":"2024-05-18T22:45:18.063277Z","shell.execute_reply.started":"2024-05-18T22:45:15.440375Z","shell.execute_reply":"2024-05-18T22:45:18.062150Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model configuration\ntext_tokenizer.pad_token = text_tokenizer.eos_token\nmodel.config.update({\n    \"vocab_size\": model.config.decoder.vocab_size,\n    \"eos_token_id\": text_tokenizer.eos_token_id,\n    \"decoder_start_token_id\": text_tokenizer.bos_token_id,\n    \"pad_token_id\": text_tokenizer.pad_token_id,\n    \"max_length\": 32,\n    \"early_stopping\": True,\n    \"no_repeat_ngram_size\": 3,\n    \"length_penalty\": 2.0,\n    \"num_beams\": 3\n})","metadata":{"_uuid":"eb0c710a-9258-48eb-ab92-e14c1e64d97e","_cell_guid":"a6faac69-b50a-4fb6-9e11-e07484584862","collapsed":false,"execution":{"iopub.status.busy":"2024-05-18T22:45:18.263582Z","iopub.execute_input":"2024-05-18T22:45:18.264277Z","iopub.status.idle":"2024-05-18T22:45:18.270988Z","shell.execute_reply.started":"2024-05-18T22:45:18.264245Z","shell.execute_reply":"2024-05-18T22:45:18.269809Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_dir = \"./model_output_ENG\"\nmodel.save_pretrained(output_dir)\nfeature_extractor.save_pretrained(output_dir)\ntext_tokenizer.save_pretrained(output_dir)","metadata":{"_uuid":"c4230294-f2f6-43ea-890c-a52cc75abec4","_cell_guid":"524b0fa1-68d3-4d3e-a4ef-2ff208e5d98c","collapsed":false,"execution":{"iopub.status.busy":"2024-05-18T22:45:18.895265Z","iopub.execute_input":"2024-05-18T22:45:18.896187Z","iopub.status.idle":"2024-05-18T22:45:21.315182Z","shell.execute_reply.started":"2024-05-18T22:45:18.896150Z","shell.execute_reply":"2024-05-18T22:45:21.312976Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\ndef postprocess_text(preds, labels):\n    preds = [pred.strip() for pred in preds]\n    labels = [label.strip() for label in labels]\n    return preds, labels","metadata":{"_uuid":"692a3c66-2fcd-4884-b405-21be63c38bba","_cell_guid":"1ee2f6f9-ead9-4bbc-95b8-d9784baa1afb","collapsed":false,"execution":{"iopub.status.busy":"2024-05-18T22:45:21.317303Z","iopub.execute_input":"2024-05-18T22:45:21.317695Z","iopub.status.idle":"2024-05-18T22:45:21.324626Z","shell.execute_reply.started":"2024-05-18T22:45:21.317659Z","shell.execute_reply":"2024-05-18T22:45:21.323513Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dataset\nclass CocoDataset(Dataset):\n    def __init__(self, coco_dir, annotation_file, split: Literal[\"train\", \"val\"] = \"train\"):\n        if split not in [\"train\", \"val\"]:\n            raise ValueError(\"Split must be 'train' or 'val'\")\n\n        self.coco_dir = coco_dir\n        with open(annotation_file, 'r') as f:\n            self.data = json.load(f)['annotations']\n        self.image_dir = os.path.join(coco_dir, f'{split}2017')\n\n        temp = pd.DataFrame(self.data).groupby(\"image_id\").agg(\n            {'id': lambda x: list(x), 'caption': lambda x: list(x)}\n        ).reset_index()\n\n        self.processed_data = [vals.to_dict() for _, vals in temp.iterrows()]\n        \n    def __len__(self):\n        return len(self.processed_data)\n\n    def __getitem__(self, idx):\n        ann = self.processed_data[idx]\n        image_path = os.path.join(self.image_dir, f'{ann[\"image_id\"]:012d}.jpg')\n        image = Image.open(image_path)\n        if image.mode != 'RGB':\n            image = image.convert('RGB')\n\n        features = feature_extractor(images=image, return_tensors=\"pt\").pixel_values.squeeze()\n        annotation = ann['caption'][np.random.randint(len(ann['caption']))]\n        text_tokens = text_tokenizer(annotation, padding=\"max_length\", max_length=48, truncation=True)\n\n        return {\n            \"labels\": text_tokens[\"input_ids\"],\n            \"pixel_values\": features,\n            \"gt_annotations\": ann['caption'],\n        }","metadata":{"_uuid":"29fdd4fb-4197-4528-abee-fe7d4cb22ef3","_cell_guid":"636706ab-937d-49b1-9a65-177703ede1c2","collapsed":false,"execution":{"iopub.status.busy":"2024-05-18T22:45:25.160254Z","iopub.execute_input":"2024-05-18T22:45:25.160660Z","iopub.status.idle":"2024-05-18T22:45:25.174780Z","shell.execute_reply.started":"2024-05-18T22:45:25.160630Z","shell.execute_reply":"2024-05-18T22:45:25.173534Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the collator\nclass CustomCollator:\n    def __call__(self, features):\n        labels = torch.tensor([f[\"labels\"] for f in features])\n        pixel_values = torch.stack([f[\"pixel_values\"] for f in features])\n        gt_annotations = [f[\"gt_annotations\"] for f in features]\n\n        return {\n            'pixel_values': pixel_values,\n            'labels': labels,\n            'gt_annotations': gt_annotations\n        }","metadata":{"_uuid":"1f9bfcd0-3a5c-4b7b-b6b5-d9ec4789544c","_cell_guid":"0fe6adba-9a46-4bbc-8c6a-b42e78d9bd65","collapsed":false,"execution":{"iopub.status.busy":"2024-05-18T22:45:25.560737Z","iopub.execute_input":"2024-05-18T22:45:25.561573Z","iopub.status.idle":"2024-05-18T22:45:25.569248Z","shell.execute_reply.started":"2024-05-18T22:45:25.561535Z","shell.execute_reply":"2024-05-18T22:45:25.568102Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Trainer setup\ntraining_args = Seq2SeqTrainingArguments(\n    predict_with_generate=True,\n    evaluation_strategy=\"steps\",\n    logging_steps=10,\n    num_train_epochs=9.0,\n    warmup_steps=1000,\n    eval_steps=5000,\n    save_steps=5000,\n    learning_rate=5e-5,\n    save_total_limit=2,\n    per_device_train_batch_size=32,\n    per_device_eval_batch_size=32,\n    output_dir=output_dir,\n    fp16=True,\n    dataloader_num_workers=2,\n    remove_unused_columns=False,\n    run_name=\"Model_Training_Run\",\n    include_inputs_for_metrics=True\n)","metadata":{"_uuid":"1f141dda-2a51-4faa-973e-a8190f82108a","_cell_guid":"22fd928b-3660-4ab5-8370-3e596d1d0a7f","collapsed":false,"execution":{"iopub.status.busy":"2024-05-18T22:46:52.665155Z","iopub.execute_input":"2024-05-18T22:46:52.666058Z","iopub.status.idle":"2024-05-18T22:46:52.697928Z","shell.execute_reply.started":"2024-05-18T22:46:52.666019Z","shell.execute_reply":"2024-05-18T22:46:52.696926Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"coco_dir = \"/kaggle/input/coco-2017-dataset/coco2017\"\npath_annot_train = (\"/kaggle/input/coco-2017-dataset/coco2017/annotations/captions_train2017.json\")\npath_annot_val = (\"/kaggle/input/coco-2017-dataset/coco2017/annotations/captions_val2017.json\")\n\nds_train = CocoDataset(\n    coco_dir=coco_dir,\n    annotation_file=path_annot_train,\n    split=\"train\",\n)\n\nds_val = CocoDataset(\n    coco_dir=coco_dir,\n    annotation_file=path_annot_val,\n    split=\"val\",\n)","metadata":{"_uuid":"4576826e-2e03-49a7-93b6-61b42850dbf2","_cell_guid":"3c5bba9b-9569-448d-bd07-6d036d7185f7","collapsed":false,"execution":{"iopub.status.busy":"2024-05-18T22:46:52.839675Z","iopub.execute_input":"2024-05-18T22:46:52.840082Z","iopub.status.idle":"2024-05-18T22:47:10.285673Z","shell.execute_reply.started":"2024-05-18T22:46:52.840050Z","shell.execute_reply":"2024-05-18T22:47:10.284485Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CustomTrainer(Seq2SeqTrainer):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.compute_metrics = self.eval_compute_metrics\n\n\n    def eval_compute_metrics(self, eval_preds):\n        \n        preds, labels, metadata = eval_preds\n        \n        ignore_pad_token_for_loss = True\n        preds, labels, _ = eval_preds\n        if isinstance(preds, tuple):\n            additional_data = preds[1]  # Adjust index based on your output structure\n            preds = preds[0]\n        else:\n            additional_data = None\n\n        decoded_preds = text_tokenizer.batch_decode(preds, skip_special_tokens=True)\n        if ignore_pad_token_for_loss:\n            labels = np.where(labels != -100, labels, text_tokenizer.pad_token_id)\n\n        decoded_labels = self.atguments_for_evaluate\n        indexes_to_print = random.sample(range(len(decoded_labels)), k=5)\n        print(\"Sample Predictions:\")\n        pprint([decoded_preds[index] for index in indexes_to_print])\n        print(\"Sample GT labels:\")\n        pprint([decoded_labels[index] for index in indexes_to_print])\n\n        result = {}\n        prediction_lens = [np.count_nonzero(pred != text_tokenizer.pad_token_id) for pred in preds]\n        result[\"gen_len\"] = np.mean(prediction_lens)\n\n        bleu_scores = {f\"BLEU_{i}\": BLEUScore(n_gram=i) for i in range(1, 5)}\n        for key, bleu in bleu_scores.items():\n            result[key] = float(bleu(decoded_preds, decoded_labels))\n            print(f\"{key}: {result[key]}\")\n\n        rouge = ROUGEScore()\n        rouge_result = rouge(decoded_preds, decoded_labels)\n\n        for key, value in rouge_result.items():\n            result[key] = value.item()\n            print(f\"{key}: {result[key]}\")\n        \n        self.atguments_for_evaluate = []\n        return result\n    \n    \n    def training_step(self, model: nn.Module, inputs: Dict[str, Union[torch.Tensor, Any]]) -> torch.Tensor:\n        \"\"\"\n        Perform a training step on a batch of inputs.\n\n        Subclass and override to inject custom behavior.\n\n        Args:\n            model (`nn.Module`):\n                The model to train.\n            inputs (`Dict[str, Union[torch.Tensor, Any]]`):\n                The inputs and targets of the model.\n\n                The dictionary will be unpacked before being fed to the model. Most models expect the targets under the\n                argument `labels`. Check your model's documentation for all accepted arguments.\n\n        Return:\n            `torch.Tensor`: The tensor with training loss on this batch.\n        \"\"\"\n        inputs.pop('gt_annotations', None)\n        model.train()\n        inputs = self._prepare_inputs(inputs)\n\n        outputs = super().training_step(model, inputs)\n        return outputs\n\n    def prediction_step(self, model, inputs,  prediction_loss_only, ignore_keys=None):\n        if hasattr(self, 'atguments_for_evaluate'):\n            pass\n        else:\n            self.atguments_for_evaluate = []\n        \n        gt_annotations = inputs.pop('gt_annotations', None)\n        self.atguments_for_evaluate.extend(gt_annotations)\n        \n        outputs = super().prediction_step(model, inputs,  prediction_loss_only, ignore_keys=None)\n        \n        if not prediction_loss_only and gt_annotations is not None:\n            if isinstance(outputs, tuple):\n                pass\n            else:\n                pass\n        inputs[\"gt_annotations\"] = gt_annotations\n        return outputs","metadata":{"_uuid":"91533318-e34f-420d-b3a2-69993e857b75","_cell_guid":"bd27417a-28e3-479f-b6af-f67202c8f140","collapsed":false,"execution":{"iopub.status.busy":"2024-05-18T22:47:10.287884Z","iopub.execute_input":"2024-05-18T22:47:10.288496Z","iopub.status.idle":"2024-05-18T22:47:10.306324Z","shell.execute_reply.started":"2024-05-18T22:47:10.288420Z","shell.execute_reply":"2024-05-18T22:47:10.305378Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"collator = CustomCollator()\ntrainer = CustomTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=ds_train,\n    eval_dataset=ds_val,\n    data_collator=collator,\n    compute_metrics=None\n)","metadata":{"_uuid":"fbe77542-f978-44e7-9e92-1419d57da123","_cell_guid":"12c400e8-6bae-42ef-a00f-1b937743dbb6","collapsed":false,"execution":{"iopub.status.busy":"2024-05-18T22:47:10.307339Z","iopub.execute_input":"2024-05-18T22:47:10.307643Z","iopub.status.idle":"2024-05-18T22:47:10.341696Z","shell.execute_reply.started":"2024-05-18T22:47:10.307617Z","shell.execute_reply":"2024-05-18T22:47:10.340771Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Start training\ntrainer.train()","metadata":{"_uuid":"42c918a1-1570-42b7-a0af-720dec401baa","_cell_guid":"bf0d35a8-7d9b-4664-9f0b-9789ea229b58","collapsed":false,"execution":{"iopub.status.busy":"2024-05-18T22:47:10.343810Z","iopub.execute_input":"2024-05-18T22:47:10.344157Z","iopub.status.idle":"2024-05-18T22:52:09.415948Z","shell.execute_reply.started":"2024-05-18T22:47:10.344124Z","shell.execute_reply":"2024-05-18T22:52:09.414512Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Start training\ntrainer.evaluate()","metadata":{"_uuid":"263ef944-52ad-44e7-a01a-765c77048576","_cell_guid":"35cc8812-c643-4d29-93df-13ad6a2239b4","collapsed":false,"execution":{"iopub.status.busy":"2024-05-18T22:52:11.841922Z","iopub.execute_input":"2024-05-18T22:52:11.842476Z","iopub.status.idle":"2024-05-18T22:54:21.652010Z","shell.execute_reply.started":"2024-05-18T22:52:11.842420Z","shell.execute_reply":"2024-05-18T22:54:21.649684Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_save = \"./final_model_beit_gpt\"\ntrainer.save_model(final_save)\ntext_tokenizer.save_pretrained(final_save)\nfeature_extractor.save_pretrained(final_save)","metadata":{"_uuid":"e5aebb4e-a92b-4e19-a392-23356507e683","_cell_guid":"78a83f0c-7728-456b-9cd1-14a56bd7cac6","collapsed":false,"execution":{"iopub.status.busy":"2024-05-18T22:55:07.179496Z","iopub.execute_input":"2024-05-18T22:55:07.179871Z","iopub.status.idle":"2024-05-18T22:55:09.092879Z","shell.execute_reply.started":"2024-05-18T22:55:07.179838Z","shell.execute_reply":"2024-05-18T22:55:09.091867Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import requests\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom transformers import GPT2TokenizerFast, BeitImageProcessor\n\nmodel_2 = VisionEncoderDecoderModel.from_pretrained(final_save)\ntokenizer_2 = GPT2TokenizerFast.from_pretrained(final_save)\nimage_processor_2 = BeitImageProcessor.from_pretrained(final_save)","metadata":{"_uuid":"91ce9930-05fc-4f00-9e0f-ad9f04873389","_cell_guid":"5935cdc6-7478-4fa5-b1fb-d0e335484771","collapsed":false,"execution":{"iopub.status.busy":"2024-05-18T22:55:09.094772Z","iopub.execute_input":"2024-05-18T22:55:09.095128Z","iopub.status.idle":"2024-05-18T22:55:15.396694Z","shell.execute_reply.started":"2024-05-18T22:55:09.095094Z","shell.execute_reply":"2024-05-18T22:55:15.395733Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# let's perform inference on an image\nurl = \"/kaggle/input/coco-2017-dataset/coco2017/test2017/000000000251.jpg\"\nimage = Image.open(url)\n\nurl = 'https://img-cdn.pixlr.com/image-generator/history/65bb506dcb310754719cf81f/ede935de-1138-4f66-8ed7-44bd16efc709/medium.webp'\nimage = Image.open(requests.get(url, stream=True).raw).convert(\"RGB\")\n\npixel_values = image_processor_2(image, return_tensors=\"pt\").pixel_values\n\n# autoregressively generate caption (uses greedy decoding by default)\ngenerated_ids = model_2.generate(pixel_values, max_length=16)\ngenerated_text = tokenizer_2.batch_decode(generated_ids, skip_special_tokens=True)[0]\nplt.imshow(image)\nprint(generated_text)","metadata":{"_uuid":"f80828e8-3cf9-40b0-a26f-a49b7430ec20","_cell_guid":"5870ce4a-a980-4b80-a3e5-994696ec5206","collapsed":false,"execution":{"iopub.status.busy":"2024-05-18T22:55:15.398381Z","iopub.execute_input":"2024-05-18T22:55:15.398698Z","iopub.status.idle":"2024-05-18T22:55:17.657960Z","shell.execute_reply.started":"2024-05-18T22:55:15.398673Z","shell.execute_reply":"2024-05-18T22:55:17.656833Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_uuid":"7cfcc40a-c75c-42f7-bdc6-28d5269524dd","_cell_guid":"0e8ffb87-c597-468f-ac9f-d09769cecaab","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}